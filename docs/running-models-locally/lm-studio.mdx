---
title: "LM Studio"
description: "A quick guide to setting up LM Studio for local AI model execution with Cline."
---

## ü§ñ Setting Up LM Studio with Cline

Run AI models locally using LM Studio with Cline.

### üìã Prerequisites

-   Windows, macOS, or Linux computer with AVX2 support
-   Cline installed in VS Code

### üöÄ Setup Steps

#### 1. Install LM Studio

-   Visit [lmstudio.ai](https://lmstudio.ai)
-   Download and install for your operating system

<Frame>
	<img src="https://storage.googleapis.com/cline_public_images/docs/assets/image%20(7).png" alt="LM Studio download page" />
</Frame>

#### 2. Launch LM Studio

-   Open the installed application
-   You'll see four tabs on the left: **Chat**, **Developer** (where you will start the server), **My Models** (where your downloaded models are stored), **Discover** (add new models)

<Frame>
	<img
		src="https://storage.googleapis.com/cline_public_images/docs/assets/image%20(10).png"
		alt="LM Studio interface overview"
	/>
</Frame>

#### 3. Download a Model

-   Browse the "Discover" page
-   Select and download your preferred model
-   Wait for download to complete

<Frame>
	<img
		src="https://storage.googleapis.com/cline_public_images/docs/assets/lm-studio-download-model.gif"
		alt="Downloading a model in LM Studio"
	/>
</Frame>

#### 4. Start the Server

-   Navigate to the "Developer" tab
-   Toggle the server switch to "Running"
-   Note: The server will run at `http://localhost:1234`

<Frame>
	<img
		src="https://storage.googleapis.com/cline_public_images/docs/assets/lm-studio-starting-server.gif"
		alt="Starting the LM Studio server"
	/>
</Frame>

#### 5. Configure Cline

1. Open VS Code
2. Click Cline settings icon
3. Select "LM Studio" as API provider
4. Select your model from the available options

<Frame>
	<img
		src="https://storage.googleapis.com/cline_public_images/docs/assets/lm-studio-select-model-cline.gif"

### üß¨ Using GPT-OSS Models (New)

You can now run the open-source `gpt-oss` family locally through LM Studio and use it in Cline with the existing **LM Studio** provider‚Äîno additional provider changes required.

#### Supported IDs

- `openai/gpt-oss-20b` ‚Äì Smaller, fits on high-end consumer GPUs / Apple Silicon (‚â•16GB VRAM recommended)
- `openai/gpt-oss-120b` ‚Äì Larger, intended for multi-GPU or high-memory setups (‚â•60GB VRAM)

#### Quick CLI Workflow

```bash
# Download (choose one)
		alt="Configuring Cline with LM Studio"
	/>
lms get openai/gpt-oss-120b

# Load the model
lms load openai/gpt-oss-20b

# (Optional) Start chat via CLI
lms chat openai/gpt-oss-20b
```

#### Enable the Local API Server
1. Open LM Studio ‚Üí Developer tab ‚Üí Start the server (defaults to `http://localhost:1234`)
2. Ensure the model is loaded (shows as Active)

#### Configure in Cline
1. Open Cline settings ‚Üí Select provider: **LM Studio**
2. If the model appears in the dropdown, select it. (Cline polls `api/v0/models`.)
3. If it does not appear yet (e.g. during initial load), manually enter the model ID: `openai/gpt-oss-20b`
4. Start a task‚ÄîCline will stream responses via the OpenAI-compatible Chat Completions endpoint exposed by LM Studio.

#### Notes & Tips
- If you change the loaded model in LM Studio, re-open the Cline settings panel to refresh the list.
- Large context failures usually mean the model was loaded with a smaller context length‚Äîreload with a larger setting or enable Compact Prompt in Cline.
- Reasoning/tool-calling features of GPT-OSS via LM Studio are limited to what LM Studio's OpenAI-compatible streaming provides; advanced `.act()` style local tool loops in LM Studio's own SDK are separate from Cline‚Äôs tool orchestration.
- No API key is required; Cline uses a placeholder when calling the local server.

#### Troubleshooting
- Empty dropdown: Confirm the LM Studio server is running and the model is fully loaded.
- Connection error: Verify the base URL (override in settings if not `http://localhost:1234`).
- Slow generation: Use the 20B model or a lower quantization variant if VRAM is constrained.

> GPT-OSS integration leverages the existing LM Studio provider‚Äîso you get this support automatically with minimal changes.
</Frame>

### ‚ö†Ô∏è Important Notes

-   Start LM Studio before using with Cline
-   Keep LM Studio running in background
-   First model download may take several minutes depending on size
-   Models are stored locally after download

### üîß Troubleshooting

1. If Cline can't connect to LM Studio:
2. Verify LM Studio server is running (check Developer tab)
3. Ensure a model is loaded
4. Check your system meets hardware requirements
